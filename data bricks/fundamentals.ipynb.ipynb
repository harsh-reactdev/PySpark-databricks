{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6697f603-042e-45bf-933d-2ec9e42f818c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765521328801}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('/Workspace/Users/harsh.reactdev@gmail.com/PySpark-databricks/data bricks/flights-larger.csv', header=True, inferSchema=True)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e599fccd-8dd5-475f-b539-2ba4171989f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23bd5e7f-473a-41a9-8663-be055a89d575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "description = df.describe()\n",
    "display(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0d2e717-3bf0-4ff8-9db4-df7ba1fe02c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "215c198d-be4c-4321-8d15-9490f2ef91b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b21b507-8c4a-4be8-b9ff-903760837be9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d475318c-53da-4155-8fcd-5e20ea7a72bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f6f8dd7-feb5-414a-8177-9545957d9c59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "collect20 = df.limit(20).collect()\n",
    "display(collect20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8217749-9fa3-4d35-b926-60b01ec37bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# select\n",
    "selects = df.select('mon', 'dow')\n",
    "display(selects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea436691-8c7b-4776-9a04-e3bde142ebd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "selectsCond = df.select(col('mon') * 5)\n",
    "display(selectsCond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f6ec69d-ac98-4d2b-98b9-2baa26f1c9ec",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1765545127533}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "selectExpr = df.selectExpr('mon * 10 as new_mon') # takes in sql expressions as arguments and executes it\n",
    "display(selectExpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9192c2fb-f893-4cad-a8e3-51bc61564d5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "withCol = df.withColumn('dowMon', col('mon') + col('dow'))\n",
    "display(withCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf858fa-b5af-41fa-ba0b-0c7d872deb4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "renameCol = df.withColumnRenamed('mon', 'mon->tue')\n",
    "display(renameCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63283df0-43e2-42e8-bec7-a0b51c3a4b63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "allOfEm = df \\\n",
    "    .select('mon', 'dow')\\\n",
    "    .withColumn('mon_new', col('mon') * 10)\\\n",
    "    .withColumnRenamed('mon_new', 'new_mon')\\\n",
    "    .drop('mon')\n",
    "\n",
    "display(allOfEm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e9f7bec-3f22-400a-b687-7362c5fc28e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, expr\n",
    "\n",
    "literal = df.withColumn('country_code', lit('IN'))\n",
    "display(literal.head(5))\n",
    "\n",
    "expression = df.withColumn('dist', expr('duration * 9'))\n",
    "display(expression.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "953e1541-be8e-4280-bf80-904ce3bb81e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered = df.filter(col('mon') > 10)\n",
    "display(filtered.take(5))\n",
    "\n",
    "filteredSql = df.filter('dom > 30 AND org == \"SFO\"')\n",
    "display(filteredSql.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fb6d721-2711-4fd9-a062-f00ea86afd9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, expr\n",
    "ifelse = df.withColumn(\n",
    "    'comfy',\n",
    "    when(col('mile') < 1000, 'short flight')\n",
    "    .when(col('mile') < 4000, 'mild')\n",
    "    .otherwise('long flight')\n",
    ")\n",
    "\n",
    "display(ifelse.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "978a4101-eb27-4ba1-b0d3-fa0ab318f79c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "casewhen = df.withColumn(\n",
    "    'comfy',\n",
    "    expr('''\n",
    "        CASE\n",
    "            when duration > 360 then 'Long'\n",
    "            when duration > 600 then 'Looong'\n",
    "            else 'Doable'\n",
    "        END\n",
    "    ''')\n",
    ")\n",
    "\n",
    "display(casewhen.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8171354a-4978-4d4b-993d-15585fd7f732",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, col\n",
    "concatenated = df.withColumn(\n",
    "    'flightCode',\n",
    "    concat(col('carrier'), col('flight'))\n",
    ")\n",
    "\n",
    "display(concatenated.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a91207aa-7e71-402e-8796-3c66734c7fd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp, to_date, col\n",
    "timed = df.withColumn(\n",
    "    'timestamp',\n",
    "    current_timestamp()\n",
    ")\n",
    "display(timed.take(5))\n",
    "\n",
    "converted = timed.withColumn(\n",
    "    'date',\n",
    "    to_date(col('timestamp'), 'mm/dd/yy')\n",
    ")\n",
    "display(converted.take(5))\n",
    "\n",
    "dated = df.withColumn(\n",
    "    'date',\n",
    "    current_date()\n",
    ")\n",
    "display(dated.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1777918a-0bba-4216-8a59-659e966c700f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array, array_contains, array_distinct, explode, arrays_zip\n",
    "\n",
    "colArr = df.withColumn(\n",
    "    'allFlights',\n",
    "    array(col('mon'), col('dom'), col('dow'))\n",
    ")\n",
    "\n",
    "display(colArr.take(5))\n",
    "\n",
    "arr_contain = df.withColumn(\n",
    "    'doesContain10',\n",
    "    array_contains(array(col('dom')), 10)\n",
    ")\n",
    "display(arr_contain.take(5))\n",
    "\n",
    "expl = df.withColumn(\n",
    "    'explode',\n",
    "    explode(array(col('mon'), col('dom'), col('dow')))\n",
    ")\n",
    "display(expl.take(10))\n",
    "\n",
    "zipped = df.withColumn(\n",
    "    'zipped',\n",
    "    arrays_zip(array([{'1': 1, '2': 2}], array(col('dow')))\n",
    ")\n",
    "display(zipped.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f21dc6e-76d0-4c53-9fef-eda7f781c28c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "\n",
    "structured = df.withColumn(\n",
    "    'structured',\n",
    "    struct(col('mon'), col('dom'), col('') )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fundamentals.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
